{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook demonstrating fitting of $hrz0$ to site data\n",
    "The below code shows how to use data from fixed-tilt experiments to compute the free parameter $hrz0$. The dust distribution is currently assumed and its parameters are defined in the file `parameters_qut_experiments.xlsx`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soiling_model.base_models as smb\n",
    "import soiling_model.fitting as smf\n",
    "import soiling_model.utilities as smu\n",
    "from matplotlib import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "rcParams['figure.figsize'] = (5, 5)\n",
    "from soiling_model.paper_specific_utilities import plot_for_paper, daily_soiling_rate, fit_quality_plots, summarize_fit_quality\n",
    "import scipy.stats as sps\n",
    "\n",
    "ls_save_file = \"../results/ls_fitting_results_qut\" # least-squares fitting results\n",
    "sp_save_file = \"../results/sp_fitting_results_qut\" # semi-physical fitting results\n",
    "cm_save_file = \"../results/cm_fitting_results_qut\" # constant model fitting results\n",
    "\n",
    "reflectometer_incidence_angle = 15 # angle of incidence of reflectometer\n",
    "reflectometer_acceptance_angle = 12.5e-3 # half acceptance angle of reflectance measurements\n",
    "k_factor = 2.404 # calibration factor for TSP measurements in experiments\n",
    "second_surf = True # True if using the second-surface model. Otherwise, use first-surface\n",
    "d = \"../data/qut/\" # directory of parameter files (be sure to follow naming convention)\n",
    "test_time_at_end = [0,0,0,0] # amount of test time to leave at the end of each file\n",
    "parameter_file = d+\"parameters_qut_experiments.xlsx\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in data and divide into training and testing\n",
    "\n",
    "Specify mirrors for training, the k-factors of the dust measurements (if any), and the type of dust measurement (PMX or TSP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_experiments = [0,1] # indices for training experiments from 0 to len(files)-1\n",
    "train_mirrors = [\"Mirror_1\"] # which mirrors within the experiments are used for training\n",
    "files_experiment,training_intervals,mirror_name_list,all_mirrors = smu.get_training_data(d,\"experiment_\")\n",
    "dust_type = \"TSP\"\n",
    "\n",
    "extract = lambda x,ind: [x[ii] for ii in ind]\n",
    "files_experiment_train = extract(files_experiment,train_experiments)\n",
    "training_intervals = extract(training_intervals,train_experiments)\n",
    "t = [t for t in train_experiments]\n",
    "training_string = \"Training: \"+str(train_mirrors)+\", Exp: \"+str(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate model and load in training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imodel = smf.SemiPhysical(parameter_file)\n",
    "sim_data_train = smb.SimulationInputs( files_experiment_train,\n",
    "                                        k_factors=k_factor,\n",
    "                                        dust_type=dust_type\n",
    "                                        )\n",
    "reflect_data_train = smb.ReflectanceMeasurements(  files_experiment_train,\n",
    "                                                    sim_data_train.time,\n",
    "                                                    number_of_measurements=9.0,\n",
    "                                                    reflectometer_incidence_angle=reflectometer_incidence_angle,\n",
    "                                                    reflectometer_acceptance_angle=reflectometer_acceptance_angle,\n",
    "                                                    import_tilts=True,\n",
    "                                                    imported_column_names=train_mirrors\n",
    "                                                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trim training data to specified ranges. The second trim ensures that the weather variables stop at the limits of the reflectance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "sim_data_train,reflect_data_train = smu.trim_experiment_data(   sim_data_train,\n",
    "                                                                reflect_data_train,\n",
    "                                                                training_intervals \n",
    "                                                            )\n",
    "                                                            \n",
    "sim_data_train,reflect_data_train = smu.trim_experiment_data(   sim_data_train,\n",
    "                                                                reflect_data_train,\n",
    "                                                                \"reflectance_data\" \n",
    "                                                            )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the total data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sim_data_total = smb.SimulationInputs( files_experiment,\n",
    "                                        k_factors=k_factor,\n",
    "                                        dust_type=dust_type\n",
    "                                        )\n",
    "\n",
    "reflect_data_total = smb.ReflectanceMeasurements(  files_experiment,\n",
    "                                                    sim_data_total.time,\n",
    "                                                    number_of_measurements=9.0,\n",
    "                                                    reflectometer_incidence_angle=reflectometer_incidence_angle,\n",
    "                                                    reflectometer_acceptance_angle=reflectometer_acceptance_angle,\n",
    "                                                    import_tilts=True,\n",
    "                                                    imported_column_names=None\n",
    "                                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii,experiment in enumerate(files_experiment_train):\n",
    "    fig,ax = smu.plot_experiment_data(sim_data_train,reflect_data_train,ii)\n",
    "    fig.suptitle(f\"Training Data for file {experiment}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute extinction weights for both simulation datasets and plot. \n",
    "Note that the extinction weights depend only on the refractive index. If the refractive index is the same for all experiments, all extinction weights will be the same (and the computation will be faster.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imodel.helios_angles(sim_data_train,reflect_data_train,second_surface=second_surf)\n",
    "imodel.helios.compute_extinction_weights(sim_data_train,imodel.loss_model,verbose=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot extinction weights and save for later, since extinction weights are the same for all files in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data_train.dust.plot_distributions(figsize=(5,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data_train.dust.plot_area_distribution(figsize=(5,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imodel.helios.plot_extinction_weights(sim_data_train,fig_kwargs={'figsize':(20,10)})\n",
    "ext_weights = imodel.helios.extinction_weighting[0].copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit non-stochastic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrz0_multi,sse_multi = imodel.fit_least_squares(sim_data_train,reflect_data_train)\n",
    "imodel.update_model_parameters(hrz0_multi)\n",
    "imodel.save(ls_save_file,\n",
    "            training_simulation_data=sim_data_train,\n",
    "            training_reflectance_data=reflect_data_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set extinction coefficients. Instead of computing, we set them directly using set_extinction_coefficients since we know that they are all the same (because the dust and acceptance angles of the measurement are all the same)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imodel.helios_angles(sim_data_total,reflect_data_total,second_surface=second_surf)\n",
    "\n",
    "# Use the below if extinction weights are not necessarily the same for each file\n",
    "# imodel.helios.compute_extinction_weights(sim_data_total,imodel.loss_model,verbose=True) \n",
    "\n",
    "# case where extinction weights are known to be the same as the ext_weights from the training file\n",
    "file_inds = np.arange(len(files_experiment))\n",
    "imodel = smu.set_extinction_coefficients(imodel,ext_weights,file_inds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax,_,_,_  = imodel.plot_soiling_factor( sim_data_total,\n",
    "                                            reflectance_data=reflect_data_total,\n",
    "                                            figsize=(20,20),\n",
    "                                            reflectance_std='measurements',\n",
    "                                            fig_title=training_string,\n",
    "                                            return_handles=True,\n",
    "                                            repeat_y_labels=False)\n",
    "# add lines indicating training times for mirrors \n",
    "# and experiments use for training.\n",
    "for ii,e in enumerate(train_experiments):\n",
    "    for jj,m in enumerate(all_mirrors):\n",
    "        if m in train_mirrors:\n",
    "            a = ax[jj,e]\n",
    "            a.axvline(x=sim_data_train.time[ii].iloc[0],ls=':',color='red')\n",
    "            a.axvline(x=sim_data_train.time[ii].iloc[-1],ls=':',color='red')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Estimation for the Stochastic Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-physical model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute deposition velocity, angles, and Mie Extinction Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imodel.helios_angles(   sim_data_train,\n",
    "                        reflect_data_train,\n",
    "                        second_surface=second_surf)\n",
    "                        \n",
    "# Use the below if extinction weights are not necessarily the same for each file\n",
    "# imodel.helios.compute_extinction_weights(   sim_data_train,\n",
    "#                                             imodel.loss_model,\n",
    "#                                             verbose=True\n",
    "#                                             )\n",
    "\n",
    "# case where extinction weights are known to be the same as the ext_weights from the training file\n",
    "file_inds = np.arange(len(files_experiment_train))\n",
    "imodel = smu.set_extinction_coefficients(imodel,ext_weights,file_inds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting\n",
    "Maximum Likelihood Estmation (MLE) only for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_param_hat,log_param_cov = imodel.fit_mle(   sim_data_train,\n",
    "                                        reflect_data_train,\n",
    "                                        transform_to_original_scale=False )\n",
    "\n",
    "s = np.sqrt(np.diag(log_param_cov))\n",
    "param_ci = log_param_hat + 1.96*s*np.array([[-1],[1]])\n",
    "lower_ci = imodel.transform_scale(param_ci[0,:])\n",
    "upper_ci = imodel.transform_scale(param_ci[1,:])\n",
    "param_hat = imodel.transform_scale(log_param_hat)\n",
    "hrz0_mle,sigma_dep_mle = param_hat\n",
    "print(f'hrz0: {hrz0_mle:.2e} [{lower_ci[0]:.2e},{upper_ci[0]:.2e}]')\n",
    "print(f'sigma_dep: {sigma_dep_mle:.2e} [{lower_ci[1]:.2e},{upper_ci[1]:.2e}] [p.p./day]')\n",
    "\n",
    "hrz0_mle,sigma_dep_mle = param_hat\n",
    "imodel.update_model_parameters(param_hat)\n",
    "imodel.save(sp_save_file,\n",
    "            log_p_hat=log_param_hat,\n",
    "            log_p_hat_cov=log_param_cov,\n",
    "            training_simulation_data=sim_data_train,\n",
    "            training_reflectance_data=reflect_data_train)\n",
    "\n",
    "_,_,_ = imodel.plot_soiling_factor( sim_data_train,\n",
    "                            reflectance_data=reflect_data_train,\n",
    "                            figsize=(10,10),\n",
    "                            reflectance_std='mean',\n",
    "                            save_path=\"../results/\",\n",
    "                            fig_title=\"On Training Data\"    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with test data and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imodel.helios_angles(   sim_data_total,\n",
    "                        reflect_data_total,\n",
    "                        second_surface=second_surf)\n",
    "\n",
    "# Use the below if extinction weights are not necessarily the same for each file\n",
    "# imodel.helios.compute_extinction_weights(   sim_data_total,\n",
    "#                                             imodel.loss_model,\n",
    "#                                             verbose=True\n",
    "#                                             )\n",
    "\n",
    "# case where extinction weights are known to be the same as the ext_weights from the training file\n",
    "file_inds = np.arange(len(files_experiment))\n",
    "imodel = smu.set_extinction_coefficients(imodel,ext_weights,file_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_total,ax_total,_,_,_   = imodel.plot_soiling_factor( sim_data_total,\n",
    "                            reflectance_data=reflect_data_total,\n",
    "                            figsize=(12,15),\n",
    "                            reflectance_std='mean',\n",
    "                            save_path=\"../results/semi_physical_fitting.png\",\n",
    "                            fig_title=training_string+\" (Semi-Physical)\",\n",
    "                            return_handles=True,\n",
    "                            repeat_y_labels=False)\n",
    "\n",
    "# add lines indicating training times for mirrors \n",
    "# and experiments use for training.\n",
    "for ii,e in enumerate(train_experiments):\n",
    "    for jj,m in enumerate(all_mirrors):\n",
    "        if m in train_mirrors:\n",
    "            a = ax_total[jj,e]\n",
    "            a.axvline(x=sim_data_train.time[ii].iloc[0],ls=':',color='red')\n",
    "            a.axvline(x=sim_data_train.time[ii].iloc[-1],ls=':',color='red')\n",
    "\n",
    "fig_total.subplots_adjust(wspace=0.1, hspace=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized reflectance plot for paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax,ref_output = plot_for_paper(    imodel,\n",
    "                            reflect_data_total,\n",
    "                            sim_data_total,\n",
    "                            train_experiments,\n",
    "                            train_mirrors,\n",
    "                            [[\"N/A\",\"N/A\",\"N/A\",\"N/A\",\"N/A\"] for m in range(4)], # note: these are not the actual orientations (the experimental values are actually the average of two orientations)\n",
    "                            legend_shift=(0,0),\n",
    "                            rows_with_legend=[2],\n",
    "                            num_legend_cols=4,\n",
    "                            plot_rh=False)\n",
    "fig.savefig(sp_save_file+\".pdf\",bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constant Mean Desposition Velocity\n",
    "### Compute deposition velocity, angles. Mie weights not needed for constant mean model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_imodel = smf.ConstantMeanDeposition(parameter_file)\n",
    "constant_imodel.helios_angles(  sim_data_train,\n",
    "                                reflect_data_train,\n",
    "                                second_surface=second_surf)\n",
    "\n",
    "# extinction weights not needed for constant mean model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting\n",
    "MLE only for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_param_hat_con,log_param_cov_con = constant_imodel.fit_mle(   sim_data_train,\n",
    "                                        reflect_data_train,\n",
    "                                        transform_to_original_scale=False)\n",
    "constant_imodel.save(   cm_save_file,\n",
    "                        log_p_hat=log_param_hat_con,\n",
    "                        log_p_hat_cov=log_param_cov_con,\n",
    "                        training_simulation_data=sim_data_train,\n",
    "                        training_reflectance_data=reflect_data_train)\n",
    "\n",
    "s_con = np.sqrt(np.diag(log_param_cov_con))\n",
    "param_ci_con = log_param_hat_con + 1.96*s_con*np.array([[-1],[1]])\n",
    "lower_ci_con = constant_imodel.transform_scale(param_ci_con[0,:])\n",
    "upper_ci_con = constant_imodel.transform_scale(param_ci_con[1,:])\n",
    "param_hat_con = constant_imodel.transform_scale(log_param_hat_con)\n",
    "mu_tilde,sigma_dep_con = param_hat_con\n",
    "print(f'mu_tilde: {mu_tilde:.2e} [{lower_ci_con[0]:.2e}, {upper_ci_con[0]:.2e}] [p.p./day]')\n",
    "print(f'sigma_dep (constant mean model): {sigma_dep_con:.2e} [{lower_ci_con[1]:.2e},{upper_ci_con[1]:.2e}] [p.p./day]')\n",
    "\n",
    "constant_imodel.update_model_parameters(param_hat_con)\n",
    "_,_,_ = constant_imodel.plot_soiling_factor(    sim_data_train,\n",
    "                                        reflectance_data=reflect_data_train,\n",
    "                                        figsize=(10,10),\n",
    "                                        reflectance_std='mean',\n",
    "                                        save_path=\"../results/\",\n",
    "                                        fig_title=\"On Training Data\"    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict with test data and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constant_imodel.helios_angles(  sim_data_total,\n",
    "                                reflect_data_total,\n",
    "                                second_surface=second_surf)\n",
    "\n",
    "# Extinction weights not needed for constant mean model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_total,ax_total,_,_,_   = constant_imodel.plot_soiling_factor(   sim_data_total,\n",
    "                                                                    reflectance_data=reflect_data_total,\n",
    "                                                                    figsize=(15,15),\n",
    "                                                                    reflectance_std='mean',\n",
    "                                                                    save_path=\"../results/constant_mean_fitting.png\",\n",
    "                                                                    fig_title=training_string+\" (Constant Mean)\",\n",
    "                                                                    return_handles=True,\n",
    "                                                                    repeat_y_labels=False)\n",
    "\n",
    "# add lines indicating training times for mirrors \n",
    "# and experiments use for training.\n",
    "for ii,e in enumerate(train_experiments):\n",
    "    for jj,m in enumerate(all_mirrors):\n",
    "        if m in train_mirrors:\n",
    "            a = ax_total[jj,e]\n",
    "            a.axvline(x=sim_data_train.time[ii].iloc[0],ls=':',color='red')\n",
    "            a.axvline(x=sim_data_train.time[ii].iloc[-1],ls=':',color='red')\n",
    "\n",
    "fig_total.subplots_adjust(wspace=0.1, hspace=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalized reflectance plots for the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax,_ = plot_for_paper(    constant_imodel,\n",
    "                            reflect_data_total,\n",
    "                            sim_data_total,\n",
    "                            train_experiments,\n",
    "                            train_mirrors,\n",
    "                            [[\"N/A\",\"N/A\",\"N/A\",\"N/A\",\"N/A\"] for m in range(4)], # note: these are not the actual orientations (the experimental values are actually the average of two orientations)\n",
    "                            legend_shift=(0,0),\n",
    "                            rows_with_legend=[2],\n",
    "                            num_legend_cols=4,\n",
    "                            plot_rh=False)\n",
    "fig.savefig(cm_save_file+\".pdf\",bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High, Medium, Low daily loss distributions from total data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers = [5,50,95.0,100]\n",
    "labels = ['Low','Medium','High','Maximum']\n",
    "colors = ['blue','green','purple','black']\n",
    "fsz=16\n",
    "\n",
    "sims,a,a2 = daily_soiling_rate(  sim_data_total,\n",
    "                            cm_save_file,\n",
    "                            M = 100000,\n",
    "                            percents=pers,\n",
    "                            dust_type=dust_type)\n",
    "# xL,xU = np.percentile(sims,[0.1,99.9])\n",
    "xL,xU = -0.25,3.0\n",
    "lg = np.linspace(xL,xU,1000)\n",
    "inc_factor = imodel.helios.inc_ref_factor[0]\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "for ii in range(sims.shape[1]):\n",
    "    ax.hist(sims[:,ii],250,density=True,\n",
    "            alpha=0.5,color=colors[ii],\n",
    "            label=labels[ii])\n",
    "\n",
    "    loc = inc_factor*mu_tilde*a[ii]\n",
    "    s2 = (inc_factor*sigma_dep_con)**2 * a2[ii]\n",
    "    dist = sps.norm(loc=loc*100,scale=np.sqrt(s2)*100)\n",
    "    ax.plot(lg,dist.pdf(lg),color=colors[ii])\n",
    "    print(f\"Loss for {labels[ii]} scenario: {loc * 100:.2f} +/- {1.96 * 100 * np.sqrt(s2):.2f}\")\n",
    "\n",
    "ax.set_xlim((xL,xU))\n",
    "ax.set_ylabel('Probability Density',fontsize=fsz+2)\n",
    "ax.set_xlabel('Loss (percentage points)',fontsize=fsz+2)\n",
    "ax.legend(fontsize=fsz)\n",
    "\n",
    "fig.set_size_inches(5,4)\n",
    "fig.savefig(\"../results/losses_qut.pdf\",dpi=300,bbox_inches='tight',pad_inches=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit Quality Assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Fit quality plots (semi-physical)\n",
    "mirror_idxs = list(range(len(all_mirrors)))\n",
    "test_experiments = [f for f in list(range(len(files_experiment))) if f not in train_experiments]\n",
    "train_mirror_idx = [m for m in mirror_idxs if all_mirrors[m] in train_mirrors]\n",
    "test_mirror_idx = [m for m in mirror_idxs if all_mirrors[m] not in train_mirrors]\n",
    "\n",
    "fig,ax = summarize_fit_quality( imodel,\n",
    "                                reflect_data_total,\n",
    "                                train_experiments,\n",
    "                                train_mirror_idx,\n",
    "                                test_mirror_idx,test_experiments,\n",
    "                                min_loss=-0.2,\n",
    "                                max_loss=6.0,\n",
    "                                save_file=sp_save_file,\n",
    "                                figsize=(10,10),\n",
    "                                include_fits=False\n",
    "                                )\n",
    "for a in ax:\n",
    "    a.set_xticks([0,2,4,6])\n",
    "    a.set_yticks([0,2,4,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(6,6))\n",
    "fit_quality_plots(imodel,\n",
    "                  reflect_data_total,\n",
    "                  test_experiments,\n",
    "                  test_mirror_idx,\n",
    "                  ax=ax,\n",
    "                  min_loss= -2,\n",
    "                  max_loss=15.0,\n",
    "                  include_fits=False,\n",
    "                  data_ls='k*',\n",
    "                  data_label=\"Testing data\",\n",
    "                  replot=True,\n",
    "                  vertical_adjust=-0.1,\n",
    "                  cumulative=True)\n",
    "\n",
    "fit_quality_plots(imodel,\n",
    "                  reflect_data_total,\n",
    "                  train_experiments,\n",
    "                  test_mirror_idx,\n",
    "                  ax=ax,\n",
    "                  min_loss= -2,\n",
    "                  max_loss=15.0,\n",
    "                  include_fits=False,\n",
    "                  data_ls='g.',\n",
    "                  data_label=\"Training (different tilts)\",\n",
    "                  replot=False,\n",
    "                  vertical_adjust=-0.05,\n",
    "                  cumulative=True)\n",
    "\n",
    "fit_quality_plots(imodel,\n",
    "                  reflect_data_total,\n",
    "                  train_experiments,\n",
    "                  train_mirror_idx,\n",
    "                  ax=ax,\n",
    "                  min_loss= -2,\n",
    "                  max_loss=15.0,\n",
    "                  include_fits=False,\n",
    "                  data_ls='m.',\n",
    "                  replot=False,\n",
    "                  data_label=\"Training\",\n",
    "                  cumulative=True)\n",
    "\n",
    "\n",
    "ax.set_xlabel(\"Measured cumulative loss\",fontsize=16)\n",
    "ax.set_ylabel(\"Predicted cumulative loss\",fontsize=16)\n",
    "fig.savefig(sp_save_file+\"_cumulative_fit_quality.pdf\",bbox_inches='tight')\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(6,6))\n",
    "fit_quality_plots(imodel,\n",
    "                  reflect_data_total,\n",
    "                  test_experiments,\n",
    "                  test_mirror_idx+train_mirror_idx,\n",
    "                  ax=ax,\n",
    "                  min_loss= -2,\n",
    "                  max_loss=6.0,\n",
    "                  include_fits=False,\n",
    "                  data_ls='k*',\n",
    "                  data_label=\"Testing data\",\n",
    "                  replot=True,\n",
    "                  vertical_adjust=-0.1,\n",
    "                  cumulative=False)\n",
    "\n",
    "fit_quality_plots(imodel,\n",
    "                  reflect_data_total,\n",
    "                  train_experiments,\n",
    "                  test_mirror_idx,\n",
    "                  ax=ax,\n",
    "                  min_loss= -2,\n",
    "                  max_loss=6.0,\n",
    "                  include_fits=False,\n",
    "                  data_ls='g.',\n",
    "                  data_label=\"Training (different tilts)\",\n",
    "                  replot=False,\n",
    "                  vertical_adjust=-0.05,\n",
    "                  cumulative=False)\n",
    "\n",
    "fit_quality_plots(imodel,\n",
    "                  reflect_data_total,\n",
    "                  train_experiments,\n",
    "                  train_mirror_idx,\n",
    "                  ax=ax,\n",
    "                  min_loss= -2,\n",
    "                  max_loss=6.0,\n",
    "                  include_fits=False,\n",
    "                  data_ls='m.',\n",
    "                  replot=False,\n",
    "                  data_label=\"Training\",\n",
    "                  cumulative=False)\n",
    "\n",
    "\n",
    "\n",
    "_ = ax.set_title(\"Loss change prediction quality assessment (semi-physical)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Fit Quality plots (constant-mean)\n",
    "fig,ax = summarize_fit_quality( constant_imodel,\n",
    "                                reflect_data_total,\n",
    "                                train_experiments,\n",
    "                                train_mirror_idx,\n",
    "                                test_mirror_idx,test_experiments,\n",
    "                                min_loss=-2,\n",
    "                                max_loss=6.0,\n",
    "                                save_file=sp_save_file,\n",
    "                                figsize=(10,10),\n",
    "                                include_fits=False)\n",
    "for a in ax:\n",
    "    a.set_xticks([0,2,4,6])\n",
    "    a.set_yticks([0,2,4,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(6,6))\n",
    "\n",
    "fit_quality_plots(constant_imodel,\n",
    "                  reflect_data_total,\n",
    "                  test_experiments,\n",
    "                  test_mirror_idx+train_mirror_idx,\n",
    "                  ax=ax,\n",
    "                  min_loss= -2,\n",
    "                  max_loss=15.0,\n",
    "                  include_fits=False,\n",
    "                  data_ls='k*',\n",
    "                  data_label=\"Testing data\",\n",
    "                  replot=True,\n",
    "                  vertical_adjust=-0.1,\n",
    "                  cumulative=True)\n",
    "\n",
    "fit_quality_plots(constant_imodel,\n",
    "                  reflect_data_total,\n",
    "                  train_experiments,\n",
    "                  test_mirror_idx,\n",
    "                  ax=ax,\n",
    "                  min_loss= -2,\n",
    "                  max_loss=15.0,\n",
    "                  include_fits=False,\n",
    "                  data_ls='g.',\n",
    "                  data_label=\"Training (different tilts)\",\n",
    "                  replot=False,\n",
    "                  vertical_adjust=-0.05,\n",
    "                  cumulative=True)\n",
    "\n",
    "fit_quality_plots(constant_imodel,\n",
    "                  reflect_data_total,\n",
    "                  train_experiments,\n",
    "                  train_mirror_idx,\n",
    "                  ax=ax,\n",
    "                  min_loss= -2,\n",
    "                  max_loss=15.0,\n",
    "                  include_fits=False,\n",
    "                  data_ls='m.',\n",
    "                  replot=False,\n",
    "                  data_label=\"Training\",\n",
    "                  cumulative=True)\n",
    "\n",
    "ax.set_xlabel(\"Measured cumulative loss\",fontsize=16)\n",
    "ax.set_ylabel(\"Predicted cumulative loss\",fontsize=16)\n",
    "fig.savefig(cm_save_file+\"_cumulative_fit_quality.pdf\",bbox_inches='tight')\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(6,6))\n",
    "fit_quality_plots(constant_imodel,\n",
    "                  reflect_data_total,\n",
    "                  test_experiments,\n",
    "                  test_mirror_idx,\n",
    "                  ax=ax,\n",
    "                  min_loss= -2,\n",
    "                  max_loss=6.0,\n",
    "                  include_fits=False,\n",
    "                  data_ls='k*',\n",
    "                  data_label=\"Testing data\",\n",
    "                  replot=True,\n",
    "                  vertical_adjust=-0.1,\n",
    "                  cumulative=False)\n",
    "\n",
    "fit_quality_plots(constant_imodel,\n",
    "                  reflect_data_total,\n",
    "                  train_experiments,\n",
    "                  test_mirror_idx,\n",
    "                  ax=ax,\n",
    "                  min_loss= -2,\n",
    "                  max_loss=6.0,\n",
    "                  include_fits=False,\n",
    "                  data_ls='g.',\n",
    "                  data_label=\"Training (different tilts)\",\n",
    "                  replot=False,\n",
    "                  vertical_adjust=-0.05,\n",
    "                  cumulative=False)\n",
    "\n",
    "fit_quality_plots(constant_imodel,\n",
    "                  reflect_data_total,\n",
    "                  train_experiments,\n",
    "                  train_mirror_idx,\n",
    "                  ax=ax,\n",
    "                  min_loss= -2,\n",
    "                  max_loss=6.0,\n",
    "                  include_fits=False,\n",
    "                  data_ls='m.',\n",
    "                  replot=False,\n",
    "                  data_label=\"Training\",\n",
    "                  cumulative=False)\n",
    "\n",
    "# ax.set_title(\"Loss change prediction quality assessment (constant mean)\")\n",
    "_ = ax.set_xlabel(r\"Measured $\\Delta$loss\")\n",
    "_ = ax.set_ylabel(r\"Predicted $\\Delta$loss\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
